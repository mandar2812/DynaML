{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.pipes.{DataPipe, MetaPipe}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.analysis\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.probability._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.graphics.plot3d\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.graphics.plot3d._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.utils\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.analysis.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.tensorflow.{dtf,dtfdata,dtfpipe,dtfutils,dtflearn}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.tensorflow.layers.{\n",
       "  L1Regularization,\n",
       "  L2Regularization\n",
       "}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.github.mandar2812.dynaml.tensorflow.pde.{source => q, _}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.org.platanios.tensorflow.api.learn.Mode\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.org.platanios.tensorflow.api.learn.layers.Layer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mammonite.ops._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.joda.time.DateTime\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.org.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.training.optimizers.Optimizer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspire.algebra.InnerProductSpace\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mrandom\u001b[39m: \u001b[32mRandom\u001b[39m = scala.util.Random@3505a241"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import _root_.io.github.mandar2812.dynaml.pipes.{DataPipe, MetaPipe}\n",
    "import _root_.io.github.mandar2812.dynaml.analysis\n",
    "import _root_.io.github.mandar2812.dynaml.probability._\n",
    "import _root_.io.github.mandar2812.dynaml.graphics.plot3d\n",
    "import _root_.io.github.mandar2812.dynaml.graphics.plot3d._\n",
    "import _root_.io.github.mandar2812.dynaml.utils\n",
    "import _root_.io.github.mandar2812.dynaml.analysis.implicits._\n",
    "import _root_.io.github.mandar2812.dynaml.tensorflow.{dtf,dtfdata,dtfpipe,dtfutils,dtflearn}\n",
    "import _root_.io.github.mandar2812.dynaml.tensorflow.layers.{\n",
    "  L1Regularization,\n",
    "  L2Regularization\n",
    "}\n",
    "import _root_.io.github.mandar2812.dynaml.tensorflow.pde.{source => q, _}\n",
    "import _root_.org.platanios.tensorflow.api.learn.Mode\n",
    "import _root_.org.platanios.tensorflow.api.learn.layers.Layer\n",
    "import ammonite.ops._\n",
    "import org.joda.time.DateTime\n",
    "import _root_.org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.ops.training.optimizers.Optimizer\n",
    "import spire.algebra.InnerProductSpace\n",
    "\n",
    "import scala.util.Random\n",
    "\n",
    "val random = new Random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mbatch\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch[T: TF: IsFloatOrDouble](\n",
    "  dim: Int,\n",
    "  min: Seq[T],\n",
    "  max: Seq[T],\n",
    "  gridSize: Int,\n",
    "  func: Seq[T] => T)(\n",
    "  implicit f: InnerProductSpace[T, Double]): (Tensor[T], Tensor[T]) = {\n",
    "\n",
    "  val points = utils.combine(\n",
    "    Seq.tabulate(dim)(\n",
    "      i =>\n",
    "        if (min(i) != max(i)) utils.range(min(i), max(i), gridSize) :+ max(i)\n",
    "        else Stream(min(i))\n",
    "    )\n",
    "  )\n",
    "\n",
    "  val targets = points.map(func)\n",
    "\n",
    "  val data_size = points.length\n",
    "\n",
    "  (\n",
    "    dtf\n",
    "      .tensor_from[T](data_size, dim)(points.flatten.toSeq),\n",
    "    dtf.tensor_from[T](data_size, 1)(targets)\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlayer\u001b[39m: \u001b[32mLayer\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = Sin"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val layer = new Layer[Output[Float], Output[Float]](\"Sin\") {\n",
    "  override val layerType = \"Sin\"\n",
    "\n",
    "  override def forwardWithoutContext(\n",
    "    input: Output[Float]\n",
    "  )(\n",
    "    implicit mode: Mode\n",
    "  ): Output[Float] =\n",
    "    tf.sin(input)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplot_field\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplot_field_snapshots\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_field(x: Tensor[Float], t: Tensor[Float]): DelauneySurface = {\n",
    "\n",
    "  val data = (0 until x.shape(0)).map(row => {\n",
    "\n",
    "    val inputs = (\n",
    "      x(row, 0).scalar.asInstanceOf[Double],\n",
    "      x(row, 1).scalar.asInstanceOf[Double]\n",
    "    )\n",
    "    val output = t(row).scalar.asInstanceOf[Double]\n",
    "\n",
    "    (inputs, output)\n",
    "  })\n",
    "\n",
    "  plot3d.draw(data)\n",
    "}\n",
    "\n",
    "def plot_field_snapshots(\n",
    "  x: Tensor[Float],\n",
    "  t: Tensor[Float]\n",
    "): Seq[(Float, DelauneySurface)] = {\n",
    "\n",
    "  x.unstack(axis = 0)\n",
    "    .zip(t.unstack(axis = 0))\n",
    "    .map(p => {\n",
    "      val t_index = p._1(0)\n",
    "      val xy      = p._1(1 ::).entriesIterator.toSeq\n",
    "      (\n",
    "        t_index.scalar.toFloat,\n",
    "        ((xy.head.toDouble, xy.last.toDouble), p._2.scalar.toDouble)\n",
    "      )\n",
    "    })\n",
    "    .groupBy(_._1)\n",
    "    .mapValues(_.map(_._2))\n",
    "    .mapValues(v => plot3d.draw(v))\n",
    "    .toSeq\n",
    "    .sortBy(_._1)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mburgers1d\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def burgers1d(\n",
    "  num_data: Int = 100,\n",
    "  num_colocation_points: Int = 10000,\n",
    "  num_neurons: Seq[Int] = Seq(5, 5),\n",
    "  optimizer: Optimizer = tf.train.Adam(0.01f),\n",
    "  iterations: Int = 50000,\n",
    "  reg: Double = 0.001,\n",
    "  reg_sources: Double = 0.001,\n",
    "  pde_wt: Double = 1.5,\n",
    "  vis: Double = 0.5,\n",
    "  q_scheme: String = \"GL\",\n",
    "  tempdir: Path = home / \"tmp\"\n",
    ") = {\n",
    "\n",
    "  val session = Session()\n",
    "\n",
    "  val summary_dir = tempdir / s\"dtf_burgers_test-${DateTime.now().toString(\"YYYY-MM-dd-HH-mm-ss\")}\"\n",
    "\n",
    "  val domain = (-5.0, 5.0)\n",
    "\n",
    "  val time_domain = (0d, 20d)\n",
    "\n",
    "  val input_dim: Int = 2\n",
    "\n",
    "  val output_dim: Int = 1\n",
    "\n",
    "  val nu = vis.toFloat\n",
    "\n",
    "  val u = 2.5f\n",
    "\n",
    "  val ground_truth = (tl: Seq[Float]) => {\n",
    "    val (t, x) = (tl.head, tl.last)\n",
    "\n",
    "    u * math.exp(-x * x / 0.5f).toFloat\n",
    "  }\n",
    "\n",
    "  val f1 = (l: Double) => u * math.exp(-l.toFloat * l.toFloat / 0.5f).toFloat\n",
    "\n",
    "  val (test_data, _) = batch[Float](\n",
    "    input_dim,\n",
    "    Seq(time_domain._1.toFloat, domain._1.toFloat),\n",
    "    Seq(time_domain._2.toFloat, domain._2.toFloat),\n",
    "    gridSize = 20,\n",
    "    ground_truth\n",
    "  )\n",
    "\n",
    "  val xs = utils.range(domain._1, domain._2, num_data) ++ Seq(domain._2) ++ Seq(\n",
    "    0d\n",
    "  )\n",
    "\n",
    "  val training_data =\n",
    "    dtfdata.supervised_dataset[Tensor[Float], Tensor[Float]](\n",
    "      data = xs.flatMap(x => {\n",
    "        Seq(\n",
    "          (\n",
    "            dtf.tensor_f32(input_dim)(0f, x.toFloat),\n",
    "            dtf.tensor_f32(output_dim)(f1(x))\n",
    "          )\n",
    "        )\n",
    "      })\n",
    "    )\n",
    "\n",
    "  val input = Shape(input_dim)\n",
    "\n",
    "  val output = Shape(output_dim)\n",
    "\n",
    "  val architecture =\n",
    "    dtflearn.feedforward_stack[Float](\n",
    "      (i: Int) =>\n",
    "        if (i == 1) tf.learn.ReLU(s\"Act_$i\") else tf.learn.Sigmoid(s\"Act_$i\")\n",
    "    )(num_neurons ++ Seq(1))\n",
    "\n",
    "  val (_, layer_shapes, layer_parameter_names, layer_datatypes) =\n",
    "    dtfutils.get_ffstack_properties(\n",
    "      d = input_dim,\n",
    "      num_pred_dims = 1,\n",
    "      num_neurons\n",
    "    )\n",
    "\n",
    "  val scope = dtfutils.get_scope(architecture) _\n",
    "\n",
    "  val layer_scopes =\n",
    "    layer_parameter_names.map(n => \"\")\n",
    "\n",
    "  val viscosity =\n",
    "    constant[Output[Float], Float](\"viscosity\", Tensor(nu).reshape(Shape()))\n",
    "\n",
    "  val burgers_equation = d_t + (d_s * I[Float, Float]()) - (d_s(d_s) * viscosity)\n",
    "\n",
    "  val (quadrature_space, quadrature_time) = if (q_scheme == \"MonteCarlo\") {\n",
    "    (\n",
    "      analysis.monte_carlo_quadrature(\n",
    "        UniformRV(domain._1, domain._2)\n",
    "      )(math.sqrt(num_colocation_points).toInt),\n",
    "      analysis.monte_carlo_quadrature(\n",
    "        UniformRV(time_domain._1, time_domain._2)\n",
    "      )(math.sqrt(num_colocation_points).toInt)\n",
    "    )\n",
    "  } else {\n",
    "    (\n",
    "      analysis.eightPointGaussLegendre.scale(domain._1, domain._2),\n",
    "      analysis.eightPointGaussLegendre.scale(time_domain._1, time_domain._2)\n",
    "    )\n",
    "  }\n",
    "\n",
    "  val (nodes, weights)     = (quadrature_space.nodes, quadrature_space.weights)\n",
    "  val (nodes_t, weights_t) = (quadrature_time.nodes, quadrature_time.weights)\n",
    "\n",
    "  val nodes_tensor: Tensor[Float] = dtf.tensor_f32(\n",
    "    nodes.length * nodes_t.length,\n",
    "    2\n",
    "  )(\n",
    "    utils.combine(Seq(nodes_t.map(_.toFloat), nodes.map(_.toFloat))).flatten: _*\n",
    "  )\n",
    "\n",
    "  val weights_tensor: Tensor[Float] =\n",
    "    dtf.tensor_f32(nodes.length * nodes_t.length)(\n",
    "      utils\n",
    "        .combine(Seq(weights_t.map(_.toFloat), weights.map(_.toFloat)))\n",
    "        .map(_.product): _*\n",
    "    )\n",
    "\n",
    "  val loss_func =\n",
    "    tf.learn.L2Loss[Float, Float](\"Loss/L2\") >>\n",
    "      tf.learn.Mean[Float](\"L2/Mean\")\n",
    "\n",
    "  val reg_y = L2Regularization[Float](\n",
    "    layer_scopes,\n",
    "    layer_parameter_names,\n",
    "    layer_datatypes,\n",
    "    layer_shapes,\n",
    "    reg\n",
    "  )\n",
    "\n",
    "  val burgers_system1d = dtflearn.pde_system[Float, Float, Float](\n",
    "    architecture,\n",
    "    burgers_equation,\n",
    "    input,\n",
    "    output,\n",
    "    loss_func,\n",
    "    nodes_tensor,\n",
    "    weights_tensor,\n",
    "    Tensor(pde_wt.toFloat).reshape(Shape()),\n",
    "    reg_f = Some(reg_y),\n",
    "    reg_v = None\n",
    "  )\n",
    "\n",
    "  val burgers_model1d = burgers_system1d.solve(\n",
    "    training_data,\n",
    "    dtflearn.model.trainConfig(\n",
    "      summary_dir,\n",
    "      dtflearn.model.data_ops(\n",
    "        training_data.size / 10,\n",
    "        training_data.size / 4,\n",
    "        10\n",
    "      ),\n",
    "      optimizer,\n",
    "      dtflearn.abs_loss_change_stop(0.001, iterations),\n",
    "      Some(dtflearn.model._train_hooks(summary_dir))\n",
    "    ),\n",
    "    dtflearn.model.tf_data_handle_ops(\n",
    "      bufferSize = training_data.size / 10,\n",
    "      patternToTensor = Some(\n",
    "        burgers_system1d.pattern_to_tensor\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "\n",
    "  print(\"Test Data Shapes: \")\n",
    "  pprint.pprintln(test_data.shape)\n",
    "\n",
    "  val predictions = burgers_model1d.predict(\"Output\")(test_data)\n",
    "\n",
    "  val plot = plot_field(test_data, predictions.head)\n",
    "\n",
    "  session.close()\n",
    "\n",
    "  (\n",
    "    burgers_system1d,\n",
    "    burgers_model1d,\n",
    "    training_data,\n",
    "    plot,\n",
    "    test_data,\n",
    "    predictions.head\n",
    "  )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J providers.\n",
      "SLF4J: Found provider [org.slf4j.log4j12.Log4j12ServiceProvider@654fb9fa]\n",
      "SLF4J: Found provider [org.slf4j.helpers.NOPServiceProvider@60d219f7]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual provider is of type [org.slf4j.log4j12.Log4j12ServiceProvider@654fb9fa]\n"
     ]
    }
   ],
   "source": [
    "val res = burgers1d(\n",
    "    num_data = 250, \n",
    "    num_colocation_points = 2500, \n",
    "    num_neurons = Seq(40, 20, 20), \n",
    "    iterations = 50000, \n",
    "    pde_wt = 10.0, \n",
    "    reg = 0.0001, \n",
    "    vis = 0.008, \n",
    "    optimizer = tf.train.AdaDelta(0.1f), \n",
    "    q_scheme = \"GL\", \n",
    "    tempdir = root/'media/'disk2/'scratch/'mandar/'tmp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "Rotate     : Left click and drag mouse\n",
      "Scale      : Roll mouse wheel\n",
      "Z Shift    : Right click and drag mouse\n",
      "Animate    : Double left click\n",
      "Screenshot : Press 's'\n",
      "\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "plot3d.show(res._4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burgers2d(\n",
    "  num_data: Int = 100,\n",
    "  num_colocation_points: Int = 10000,\n",
    "  num_neurons: Seq[Int] = Seq(5, 5),\n",
    "  optimizer: Optimizer = tf.train.Adam(0.01f),\n",
    "  iterations: Int = 50000,\n",
    "  reg: Double = 0.001,\n",
    "  reg_sources: Double = 0.001,\n",
    "  pde_wt: Double = 1.5,\n",
    "  vis: Double = 0.5,\n",
    "  q_scheme: String = \"GL\",\n",
    "  tempdir: Path = home / \"tmp\"\n",
    ") = {\n",
    "\n",
    "  val session = Session()\n",
    "\n",
    "  val summary_dir = tempdir / s\"dtf_burgers2d_test-${DateTime.now().toString(\"YYYY-MM-dd-HH-mm-ss\")}\"\n",
    "\n",
    "  val domain = (-5.0, 5.0)\n",
    "\n",
    "  val time_domain = (0d, 20d)\n",
    "\n",
    "  val input_dim: Int = 3\n",
    "\n",
    "  val output_dim: Int = 1\n",
    "\n",
    "  val nu = vis.toFloat\n",
    "\n",
    "  val u = 2.5f\n",
    "\n",
    "  val ground_truth = (tl: Seq[Float]) => {\n",
    "    val (t, x) = (tl.head, tl.tail)\n",
    "\n",
    "    u * math.exp(-x.map(x => x * x).sum / 2f).toFloat\n",
    "  }\n",
    "\n",
    "  val f1 = (l: Seq[Double]) => u * math.exp(-l.map(x => x * x).sum / 2f).toFloat //if (l == 0d) u else 0f\n",
    "\n",
    "  val initial_cond_plot = plot3d.draw(\n",
    "    (x, y) => f1(Seq(x, y)).toFloat,\n",
    "    (domain._1.toFloat, domain._2.toFloat),\n",
    "    (domain._1.toFloat, domain._2.toFloat)\n",
    "  )\n",
    "\n",
    "  val (test_data, _) = batch[Float](\n",
    "    input_dim,\n",
    "    Seq(time_domain._1.toFloat, domain._1.toFloat, domain._1.toFloat),\n",
    "    Seq(time_domain._2.toFloat, domain._2.toFloat, domain._2.toFloat),\n",
    "    gridSize = 10,\n",
    "    ground_truth\n",
    "  )\n",
    "\n",
    "  val xs = utils.range(domain._1, domain._2, num_data) ++ Seq(domain._2) ++ Seq(\n",
    "    0d\n",
    "  )\n",
    "\n",
    "  val xsys = utils.combine(Seq(xs, xs))\n",
    "\n",
    "  val training_data =\n",
    "    dtfdata.supervised_dataset[Tensor[Float], Tensor[Float]](\n",
    "      data = xsys.flatMap(xy => {\n",
    "        Seq(\n",
    "          (\n",
    "            dtf.buffer_f32(\n",
    "              Shape(input_dim),\n",
    "              Array(0f) ++ xy.map(_.toFloat).toArray[Float]\n",
    "            ),\n",
    "            dtf.tensor_f32(output_dim)(f1(xy))\n",
    "          )\n",
    "        )\n",
    "      })\n",
    "    )\n",
    "\n",
    "  val input = Shape(input_dim)\n",
    "\n",
    "  val output = Shape(output_dim)\n",
    "\n",
    "  val architecture =\n",
    "    dtflearn.rbf_layer[Float](\"RBF\", num_neurons.head, dtflearn.rbf_layer.InverseMultiQuadric) >>\n",
    "    dtflearn.feedforward_stack[Float](\n",
    "      (i: Int) =>\n",
    "        if (i == 1) tf.learn.ReLU(s\"Act_$i\", 0.01f)\n",
    "        else tf.learn.Sigmoid(s\"Act_$i\")\n",
    "    )(num_neurons.tail ++ Seq(1))\n",
    "\n",
    "  val (_, layer_shapes, layer_parameter_names, layer_datatypes) =\n",
    "    dtfutils.get_ffstack_properties(\n",
    "      d = num_neurons.head,\n",
    "      num_pred_dims = 1,\n",
    "      num_neurons.tail\n",
    "    )\n",
    "\n",
    "  val scope = dtfutils.get_scope(architecture) _\n",
    "\n",
    "  val layer_scopes =\n",
    "    layer_parameter_names.map(n => \"\")\n",
    "\n",
    "  val viscosity =\n",
    "    constant[Output[Float], Float](\"viscosity\", Tensor(nu).reshape(Shape()))\n",
    "\n",
    "  val d_x = ∂[Float](\"D_x\")(1)(---)\n",
    "  val d_y = ∂[Float](\"D_y\")(2)(---)\n",
    "\n",
    "  val burgers_equation = d_t + (d_x * I[Float, Float]()) - (d_x(d_x) + d_y(d_y)) * viscosity\n",
    "\n",
    "  val (quadrature_space, quadrature_time) = if (q_scheme == \"MonteCarlo\") {\n",
    "    val time_n = UniformRV(time_domain._1, time_domain._2)\n",
    "      .iid(math.pow(num_colocation_points, 1d / input_dim).toInt)\n",
    "      .draw\n",
    "      .toSeq\n",
    "    val space_n = UniformRV(domain._1, domain._2)\n",
    "      .iid(math.pow(num_colocation_points, 1d / input_dim).toInt)\n",
    "      .draw\n",
    "      .toSeq\n",
    "\n",
    "    (\n",
    "      analysis.MonteCarloQuadrature(space_n),\n",
    "      analysis.MonteCarloQuadrature(time_n)\n",
    "    )\n",
    "  } else {\n",
    "    (\n",
    "      analysis.eightPointGaussLegendre.scale(domain._1, domain._2),\n",
    "      analysis.eightPointGaussLegendre.scale(time_domain._1, time_domain._2)\n",
    "    )\n",
    "  }\n",
    "\n",
    "  val (nodes, weights)     = (quadrature_space.nodes, quadrature_space.weights)\n",
    "  val (nodes_t, weights_t) = (quadrature_time.nodes, quadrature_time.weights)\n",
    "\n",
    "  val nodes_tensor: Tensor[Float] = dtf.tensor_f32(\n",
    "    nodes.length * nodes.length * nodes_t.length,\n",
    "    input_dim\n",
    "  )(\n",
    "    utils\n",
    "      .combine(\n",
    "        Seq(nodes_t.map(_.toFloat), nodes.map(_.toFloat), nodes.map(_.toFloat))\n",
    "      )\n",
    "      .flatten: _*\n",
    "  )\n",
    "\n",
    "  val weights_tensor: Tensor[Float] =\n",
    "    dtf.tensor_f32(nodes.length * nodes.length * nodes_t.length)(\n",
    "      utils\n",
    "        .combine(\n",
    "          Seq(\n",
    "            weights_t.map(_.toFloat),\n",
    "            weights.map(_.toFloat),\n",
    "            weights.map(_.toFloat)\n",
    "          )\n",
    "        )\n",
    "        .map(_.product): _*\n",
    "    )\n",
    "\n",
    "  val loss_func =\n",
    "    tf.learn.L2Loss[Float, Float](\"Loss/L2\") >>\n",
    "      tf.learn.Mean[Float](\"L2/Mean\")\n",
    "\n",
    "  val reg_y = L2Regularization[Float](\n",
    "    layer_scopes,\n",
    "    layer_parameter_names,\n",
    "    layer_datatypes,\n",
    "    layer_shapes,\n",
    "    reg\n",
    "  )\n",
    "\n",
    "  val burgers_system2d = dtflearn.pde_system[Float, Float, Float](\n",
    "    architecture,\n",
    "    burgers_equation,\n",
    "    input,\n",
    "    output,\n",
    "    loss_func,\n",
    "    nodes_tensor,\n",
    "    weights_tensor,\n",
    "    Tensor(pde_wt.toFloat).reshape(Shape()),\n",
    "    reg_f = Some(reg_y),\n",
    "    reg_v = None\n",
    "  )\n",
    "\n",
    "  val burgers_model2d = burgers_system2d.solve(\n",
    "    training_data,\n",
    "    dtflearn.model.trainConfig(\n",
    "      summary_dir,\n",
    "      dtflearn.model.data_ops(\n",
    "        training_data.size / 10,\n",
    "        training_data.size / 4,\n",
    "        10\n",
    "      ),\n",
    "      optimizer,\n",
    "      dtflearn.abs_loss_change_stop(0.001, iterations),\n",
    "      Some(dtflearn.model._train_hooks(summary_dir))\n",
    "    ),\n",
    "    dtflearn.model.tf_data_handle_ops(\n",
    "      bufferSize = training_data.size / 10,\n",
    "      patternToTensor = Some(\n",
    "        burgers_system2d.pattern_to_tensor\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "\n",
    "  print(\"Test Data Shapes: \")\n",
    "  pprint.pprintln(test_data.shape)\n",
    "\n",
    "  val predictions = burgers_model2d.predict(\"Output\")(test_data)\n",
    "\n",
    "  val r = predictions.head.rank\n",
    "  val plot = plot_field_snapshots(\n",
    "    test_data,\n",
    "    if (r > 2) predictions.head(0) else predictions.head\n",
    "  )\n",
    "\n",
    "  session.close()\n",
    "\n",
    "  (\n",
    "    initial_cond_plot,\n",
    "    burgers_system2d,\n",
    "    burgers_model2d,\n",
    "    training_data,\n",
    "    plot,\n",
    "    test_data,\n",
    "    if (r > 2) predictions.head(0) else predictions.head\n",
    "  )\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dynaml/Scala",
   "language": "scala",
   "name": "dynaml-scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
